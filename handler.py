#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RunPod GPU-serverless handler  Â·  EchoMimicV2
------------------------------------------------
å†·å¯åŠ¨ï¼š
    â€¢ æ¢æµ‹ç½‘ç»œå· â†’ æ ¡éªŒå¯å†™ & ç©ºé—´
    â€¢ ä¸‹è½½ / ç¼“å­˜æ¨¡å‹åˆ°å·
    â€¢ æ„å»º EchoMimicV2 Pipeline
è¯·æ±‚ï¼š
    â€¢ è§£æ payload âœ _infer âœ è¿”å› Base64-MP4

2025-04-25  ç®€åŒ–å†…å®¹
    â€¢ å‡è®¾ audio å­—æ®µå§‹ç»ˆä¸º Base-64 WAVï¼›è‹¥è§£ç å¤±è´¥åˆ™ç›´æ¥æŠ¥é”™
    â€¢ _decode_base64_audio() å–ä»£ä¹‹å‰çš„ _resolve_media() è·¯å¾„æ£€æµ‹
    â€¢ pose ä¿æŒå…¼å®¹ï¼šä»å¯æ¥å—ç›®å½•ã€zip æˆ– Base-64
"""

from __future__ import annotations

import base64
import errno
import logging
import os
import shutil
import subprocess
import sys
import time
import traceback
from pathlib import Path
from typing import Any, Dict, Optional
from fractions import Fraction

import textwrap


import numpy as np
import runpod
import torch
from diffusers import AutoencoderKL, DDIMScheduler, LCMScheduler
from omegaconf import OmegaConf
from PIL import Image
from torch.nn import functional as F

# EchoMimicV2 ç›¸å…³
from src.models.unet_2d_condition import UNet2DConditionModel
from src.models.unet_3d_emo import EMOUNet3DConditionModel
from src.models.whisper.audio2feature import load_audio_model
from src.pipelines.pipeline_echomimicv2_acc import EchoMimicV2Pipeline
from src.models.pose_encoder import PoseEncoder
from src.utils.dwpose_util import draw_pose_select_v2
from src.utils.util import save_videos_grid

# ---------------------------------------------------------------------
# å…¨å±€å˜é‡ä¸é…ç½®
# ---------------------------------------------------------------------
VOLUME_ROOT: Optional[Path] = None
for _p in (Path("/runpod-volume"), Path("/workspace")):
    if _p.exists():
        VOLUME_ROOT = _p
        break
if VOLUME_ROOT is None:
    raise RuntimeError("âŒ Network Volume æœªæŒ‚è½½åˆ° /runpod-volume æˆ– /workspace")

WEIGHTS_ROOT = VOLUME_ROOT / "pretrained_weights"
_MIN_FREE_GB = 10
_MODELS_READY = False
_PIPELINE: Optional[EchoMimicV2Pipeline] = None
_CONFIG_YAML = Path("configs/prompts/handler_config.yaml")

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
log = logging.getLogger("handler")


def _dump_env():
    log.info("==== ENV ====")
    for k in ("NVIDIA_VISIBLE_DEVICES", "NVIDIA_DRIVER_CAPABILITIES", "VK_ICD_FILENAMES"):
        log.info("%s=%s", k, os.getenv(k))

def _try(cmd):
    log.info(">> %s", " ".join(cmd))
    try:
        out = subprocess.check_output(cmd, text=True, stderr=subprocess.STDOUT, timeout=10)
        log.info(textwrap.indent(out, "   "))
    except subprocess.CalledProcessError as e:
        log.warning("ret=%s\n%s", e.returncode, e.output)
    except FileNotFoundError:
        log.warning("command not found")

_dump_env()
_try(["ls", "-l", "/usr/local/nvidia/icd.d"])
_try(["ls", "-l", "/usr/share/vulkan/icd.d"])
_try(["vulkaninfo", "--summary"])

# ---------------------------------------------------------------------
# æ¨¡å‹ä¸‹è½½ä¸ç¼“å­˜
# ---------------------------------------------------------------------

def _check_volume() -> None:
    test = VOLUME_ROOT / ".rw_test"
    try:
        test.write_text("ok"); test.unlink()
    except Exception as e:
        raise RuntimeError(f"{VOLUME_ROOT} åªè¯»æˆ–ä¸å¯å†™: {e}")
    free_gb = shutil.disk_usage(VOLUME_ROOT).free / 1024**3
    log.info("Free space on %s: %.1f GB", VOLUME_ROOT, free_gb)
    if free_gb < _MIN_FREE_GB:
        raise RuntimeError(f"å‰©ä½™ç©ºé—´ä¸è¶³ï¼Œéœ€ â‰¥ {_MIN_FREE_GB} GBï¼Œå½“å‰ {free_gb:.1f} GB")


def _git_clone_lfs(repo: str, dst: Path) -> None:
    if dst.exists():
        return
    env = os.environ | {"GIT_LFS_SKIP_SMUDGE": "1"}
    subprocess.run(["git", "clone", "--depth", "1", repo, dst], check=True, env=env)
    subprocess.run(["git", "-C", dst, "lfs", "pull"], check=True)


def _download_models() -> None:
    """ä¸€æ¬¡æ€§ä¸‹è½½ / ç¼“å­˜æ¨¡å‹åˆ°ç½‘ç»œå·ã€‚"""
    global _MODELS_READY
    if _MODELS_READY:
        return
    _check_volume()
    log.info("ğŸ“¥ Downloading models â†’ %s", WEIGHTS_ROOT)
    audio_dir = WEIGHTS_ROOT / "audio_processor"
    audio_dir.mkdir(parents=True, exist_ok=True)

    # 1) Clone EchoMimicV2 åˆ°å­ç›®å½•
    repo_dir = WEIGHTS_ROOT / "EchoMimicV2"
    try:
        _git_clone_lfs("https://huggingface.co/BadToBest/EchoMimicV2", repo_dir)
        log.info("âœ… EchoMimicV2 ä»“åº“å…‹éš†æˆåŠŸ: %s", repo_dir)
    except Exception as e:
        log.error("âŒ EchoMimicV2 ä»“åº“å…‹éš†å¤±è´¥: %s", e)
        raise

    # VAE
    _git_clone_lfs("https://huggingface.co/stabilityai/sd-vae-ft-mse", WEIGHTS_ROOT / "sd-vae-ft-mse")
    # å›¾åƒå˜ä½“
    _git_clone_lfs(
        "https://huggingface.co/lambdalabs/sd-image-variations-diffusers",
        WEIGHTS_ROOT / "sd-image-variations-diffusers",
    )
    # Whisper tiny
    tiny = audio_dir / "tiny.pt"
    if not tiny.exists():
        subprocess.run([
            "wget", "-q", "-O", tiny,
            "https://openaipublic.azureedge.net/main/whisper/models/"
            "65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt",
        ], check=True)
    log.info("âœ… Models ready.")
    _MODELS_READY = True

# ---------------------------------------------------------------------
# ç®¡é“æ„å»º
# ---------------------------------------------------------------------

def _abs(p: str | Path) -> str:
    p = Path(p)
    if "pretrained_weights" in str(p):
        return str(p.resolve()) if p.exists() else str(VOLUME_ROOT / p)
    return str(p) if p.is_absolute() else str((WEIGHTS_ROOT / p).resolve())


def _build_pipeline() -> EchoMimicV2Pipeline:
    cfg = OmegaConf.load(str(_CONFIG_YAML))
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if cfg.weight_dtype == "fp16" else torch.float32
    for key in (
        "pretrained_vae_path", "pretrained_base_model_path",
        "denoising_unet_path", "reference_unet_path",
        "pose_encoder_path", "motion_module_path", "audio_model_path",
    ):
        cfg[key] = _abs(cfg[key])
    inf_cfg = OmegaConf.load(_abs(cfg.inference_config))

    vae = AutoencoderKL.from_pretrained(cfg.pretrained_vae_path).to(device, dtype=dtype)
    try:
        ref_unet = UNet2DConditionModel.from_pretrained(
            cfg.pretrained_base_model_path,
            subfolder="unet",
            use_safetensors=True,
        ).to(device, dtype=dtype)
    except Exception:
        ref_unet = UNet2DConditionModel.from_pretrained(
            cfg.pretrained_base_model_path,
            subfolder="unet",
            use_safetensors=False,
            weight_name="diffusion_pytorch_model.bin",
        ).to(device, dtype=dtype)
    ref_unet.load_state_dict(torch.load(cfg.reference_unet_path, map_location="cpu"))

    if Path(cfg.motion_module_path).exists():
        denoise_unet = EMOUNet3DConditionModel.from_pretrained_2d(
            cfg.pretrained_base_model_path,
            cfg.motion_module_path,
            subfolder="unet",
            unet_additional_kwargs=inf_cfg.unet_additional_kwargs,
        ).to(device, dtype=dtype)
    else:
        denoise_unet = EMOUNet3DConditionModel.from_pretrained_2d(
            cfg.pretrained_base_model_path,
            "",
            subfolder="unet",
            unet_additional_kwargs={
                "use_motion_module": False,
                "unet_use_temporal_attention": False,
                "cross_attention_dim": inf_cfg.unet_additional_kwargs.cross_attention_dim,
            },
        ).to(device, dtype=dtype)
    denoise_unet.load_state_dict(
        torch.load(cfg.denoising_unet_path, map_location="cpu"), strict=False,
    )

    pose_enc = PoseEncoder(320, conditioning_channels=3, block_out_channels=(16, 32, 96, 256))
    pose_enc.load_state_dict(torch.load(cfg.pose_encoder_path, map_location="cpu"))
    pose_enc.to(device, dtype=dtype)

    sched_kwargs = OmegaConf.to_container(inf_cfg.noise_scheduler_kwargs)

    audio_model = load_audio_model(cfg.audio_model_path, device=device)
    sampler_name = getattr(inf_cfg, "sampler", "ddim").lower()
    if sampler_name == "lcm":
        log.info("Using LCMScheduler (â‰¤8 step)")
        scheduler = LCMScheduler(**sched_kwargs)
    else:
        scheduler = DDIMScheduler(**sched_kwargs)


    pipe = EchoMimicV2Pipeline(
        vae=vae,
        reference_unet=ref_unet,
        denoising_unet=denoise_unet,
        audio_guider=audio_model,
        pose_encoder=pose_enc,
        scheduler=scheduler,
    ).to(device, dtype=dtype)

    return pipe

# ---------------------------------------------------------------------
# å·¥å…·å‡½æ•°
# ---------------------------------------------------------------------

def _looks_like_local_file(p: str) -> bool:
    """ç²—ç•¥åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦å¯èƒ½æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ã€‚é¿å…æŠŠ Base64 é•¿ä¸²å½“ä½œè·¯å¾„ã€‚"""
    if not isinstance(p, str):
        return False
    if len(p) > 255:
        return False
    if p.startswith(("data:", "http://", "https://")):
        return False
    return any(ch in p for ch in ("/", "\\", "."))


def _save_b64_to_tmp(tmp: Path, b64: str, ext: str) -> Path:
    """å°† Base-64 æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼Œè¿”å›è·¯å¾„ã€‚"""
    fpath = tmp / f"blob{ext}"
    data = b64.split(",", 1)[-1]
    fpath.write_bytes(base64.b64decode(data))
    return fpath


def _save_b64(b64: str, ext: str) -> Path:
    import tempfile, uuid
    # ä½¿ç”¨ tempfile ç”Ÿæˆä¸´æ—¶ç›®å½•ï¼Œé¿å…è·¯å¾„è¿‡é•¿
    tmp_dir = Path(tempfile.mkdtemp(prefix="runpod_"))
    # ç”Ÿæˆç®€çŸ­éšæœºæ–‡ä»¶å
    filename = f"media_{int(time.time()*1000)}_{uuid.uuid4().hex[:8]}{ext}"
    fpath = tmp_dir / filename
    try:
        data = b64.split(",", 1)[-1]
        fpath.write_bytes(base64.b64decode(data))
    except Exception as e:
        raise ValueError("è§£ç  Base-64 å¤±è´¥ï¼Œè¯·ç¡®è®¤ audio å­—æ®µæ˜¯å¦ä¸ºæ­£ç¡®çš„ Base64-WAV") from e
    return fpath


def _decode_base64_audio(raw: str) -> Path:
    """å§‹ç»ˆå°† raw å½“ä½œ Base-64 WAVï¼Œå¦‚æœæ— æ³•è§£ç åˆ™æŠ› ValueError"""
    return _save_b64(raw, ".wav")



from fractions import Fraction
import subprocess, shutil, tempfile, time, math
from pathlib import Path

def _run(cmd, **kwargs):
    """
    subprocess.run() çš„è½»é‡å°è£…ï¼Œé»˜è®¤ check=Trueï¼Œ
    å…¶ä½™å…³é”®å­—å‚æ•°ï¼ˆcapture_outputã€text ç­‰ï¼‰å¯è‡ªç”±é€ä¼ 
    """
    kwargs.setdefault("check", True)
    return subprocess.run(cmd, **kwargs)

def _enhance_video_frames(
    input_video: Path,
    output_video: Path,
    target_fps: int | None = None,
    original_fps: int | None = None,
):
    """ä½¿ç”¨ RIFE æ¨¡å‹ç®€åŒ–æ’å¸§ï¼Œç±»ä¼¼äºå‘½ä»¤è¡Œè°ƒç”¨æ–¹å¼"""
    
    # ç¡®å®šæ’å¸§å€ç‡
    if original_fps is None or target_fps is None:
        # è·å–åŸå§‹è§†é¢‘å¸§ç‡
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-select_streams", "v:0", "-show_entries", 
             "stream=r_frame_rate", "-of", "default=noprint_wrappers=1:nokey=1", str(input_video)],
            capture_output=True, text=True, check=True
        )
        fps_str = probe.stdout.strip()
        num, den = map(int, fps_str.split('/'))
        original_fps = num / den if den else num
        
        if target_fps is None:
            target_fps = original_fps * 2
    
    # è®¡ç®—å¹‚æ¬¡
    mult = target_fps / original_fps
    exp = int(np.log2(mult))
    if 2**exp != mult:
        log.warning(f"ç›®æ ‡å¸§ç‡ {target_fps} ä¸æ˜¯åŸå¸§ç‡ {original_fps} çš„2çš„å¹‚æ¬¡å€ï¼Œå°†ä½¿ç”¨ {2**exp}x")
    
    log.info(f"ä½¿ç”¨ RIFE è¿›è¡Œè§†é¢‘æ’å¸§ï¼Œexp={exp}ï¼Œä» {original_fps}fps åˆ° {original_fps*(2**exp)}fps")
    
    # éªŒè¯ RIFE ç¯å¢ƒ
    try:
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„è€Œéç»å¯¹è·¯å¾„
        # æ ¹æ®handler.pyçš„ä½ç½®è·å–RIFEç›®å½•
        current_dir = Path(__file__).parent  # handler.pyæ‰€åœ¨ç›®å½•
        rife_dir = current_dir / "rife" / "ECCV2022-RIFE"
        
        log.info(f"æ­£åœ¨æŸ¥æ‰¾RIFEç›®å½•: {rife_dir}")
        
        if not rife_dir.exists():
            log.error(f"RIFE ç›®å½•ä¸å­˜åœ¨: {rife_dir}")
            # å°è¯•å¤‡ç”¨è·¯å¾„
            alt_path = Path("rife/ECCV2022-RIFE")
            if alt_path.exists():
                rife_dir = alt_path
                log.info(f"æ‰¾åˆ°å¤‡ç”¨RIFEç›®å½•: {rife_dir}")
            else:
                raise FileNotFoundError(f"RIFE ç›®å½•ä¸å­˜åœ¨: {rife_dir}")
        
        # æ£€æŸ¥ RIFE æ‰€éœ€çš„æ¨¡å‹æ–‡ä»¶
        model_path = rife_dir / "train_log"
        if not model_path.exists():
            log.error(f"RIFE æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
            # å°è¯•å½“å‰ç›®å½•ä¸‹çš„train_logè·¯å¾„
            alt_model_path = current_dir / "rife" / "ECCV2022-RIFE" / "train_log"
            if alt_model_path.exists():
                model_path = alt_model_path
                log.info(f"æ‰¾åˆ°å¤‡ç”¨æ¨¡å‹ç›®å½•: {model_path}")
            else:
                raise FileNotFoundError(f"RIFE æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
        
        # æ£€æŸ¥ inference_video.py æ˜¯å¦å­˜åœ¨
        rife_script = rife_dir / "inference_video.py"
        if not rife_script.exists():
            log.error(f"RIFE è„šæœ¬ä¸å­˜åœ¨: {rife_script}")
            raise FileNotFoundError(f"RIFE è„šæœ¬ä¸å­˜åœ¨: {rife_script}")
    except Exception as e:
        log.error(f"RIFE ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")
        raise
    
    # å‡†å¤‡ä¸´æ—¶ç›®å½•ç”¨äºè¾“å‡º
    tmp_dir = Path(tempfile.mkdtemp(prefix="rife_"))
    tmp_output = tmp_dir / "rife_output.mp4"
    
    try:
        # è°ƒç”¨ RIFE è¿›è¡Œæ’å¸§
        cmd = [
            "python", "inference_video.py",  # åªä½¿ç”¨æ–‡ä»¶å
            "--exp", str(exp),
            "--video", str(input_video),
            "--output", str(tmp_output)
        ]
        log.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        process = subprocess.run(cmd, 
                                capture_output=True, 
                                text=True,
                                cwd=str(rife_dir),  # è®¾ç½®å·¥ä½œç›®å½•
                                check=False)
        
        log.info(f"RIFE æ ‡å‡†è¾“å‡º:\n{process.stdout}")
        if process.stderr:
            log.error(f"RIFE é”™è¯¯è¾“å‡º:\n{process.stderr}")
        
        # æ£€æŸ¥è¿”å›ç 
        if process.returncode != 0:
            log.error(f"RIFE å‘½ä»¤è¿”å›éé›¶çŠ¶æ€ç : {process.returncode}")
            raise RuntimeError(f"RIFE å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼ŒçŠ¶æ€ç : {process.returncode}")
        
        # æ£€æŸ¥è¾“å‡ºè§†é¢‘æ˜¯å¦å­˜åœ¨
        if not tmp_output.exists() or tmp_output.stat().st_size == 0:
            raise RuntimeError("RIFE æ’å¸§å¤±è´¥ï¼Œè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
        
        # è½¬ç§»éŸ³é¢‘
        _transfer_audio(input_video, tmp_output, output_video)
        
    except Exception as e:
        log.error(f"RIFE æ’å¸§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        # å¦‚æœæ’å¸§å¤±è´¥ï¼Œåˆ™ä½¿ç”¨åŸå§‹è§†é¢‘
        shutil.copy(input_video, output_video)
        log.warning("æ’å¸§å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹è§†é¢‘")
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(tmp_dir, ignore_errors=True)

def _transfer_audio(source_video, target_video, final_output):
    """ä»æºè§†é¢‘è½¬ç§»éŸ³é¢‘åˆ°ç›®æ ‡è§†é¢‘"""
    try:
        # åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘
        subprocess.run([
            "ffmpeg", "-y", "-i", str(target_video), 
            "-i", str(source_video), 
            "-c:v", "copy", "-c:a", "aac", 
            "-map", "0:v:0", "-map", "1:a:0?",
            str(final_output)
        ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if not final_output.exists() or final_output.stat().st_size == 0:
            log.warning("éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œå°†ä½¿ç”¨æ— éŸ³é¢‘è§†é¢‘")
            shutil.copy(target_video, final_output)
            
    except Exception as e:
        log.warning(f"éŸ³é¢‘è½¬ç§»å¤±è´¥: {e}")
        # å¦‚æœéŸ³é¢‘è½¬ç§»å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨æ— éŸ³é¢‘çš„è§†é¢‘
        shutil.copy(target_video, final_output)

# ---------------------------------------------------------------------
# æ¨ç†æ ¸å¿ƒ
# ---------------------------------------------------------------------

def _infer(payload: Dict[str, Any]) -> Dict[str, Any]:
    global _PIPELINE
    if _PIPELINE is None:
        log.info("é¦–æ¬¡è°ƒç”¨ï¼Œè¿›è¡Œå†·å¯åŠ¨æ„å»ºç®¡é“")
        _download_models()
        _PIPELINE = _build_pipeline()

    defaults = OmegaConf.load(str(_CONFIG_YAML)).default_params
    refimg = Path("assets/refimag_teacher_v3.png")
    if not refimg.exists():
        raise FileNotFoundError(f"å‚è€ƒå›¾åƒä¸å­˜åœ¨: {refimg}")

    # è½¬æ¢ä¸ºPILå›¾åƒå¯¹è±¡
    ref_img_pil = Image.open(refimg).convert("RGB")

    # å‡è®¾ API ä¼ å…¥çš„ audio å­—æ®µå§‹ç»ˆä¸º Base-64 ç¼–ç çš„ WAVï¼Œç›´æ¥è§£ç 
    raw_audio = payload.get("audio")
    if not raw_audio:
        raise ValueError("ç¼ºå°‘å‚æ•°: audio")
    audio_path = _decode_base64_audio(raw_audio)

    # å…¶å®ƒå‚æ•°
    W = int(payload.get("width", payload.get("W", defaults.width)))
    H = int(payload.get("height", payload.get("H", defaults.height)))
    steps = int(payload.get("steps", defaults.steps))
    cfg_scale = float(payload.get("guidance_scale", defaults.guidance_scale))
    fps = int(payload.get("fps", defaults.fps))
    seed = int(payload.get("seed", defaults.seed))
    length = int(payload.get("length", defaults.length))
    ctx_f = int(payload.get("context_frames", defaults.context_frames))
    ctx_o = int(payload.get("context_overlap", defaults.context_overlap))
    sr = int(payload.get("sample_rate", defaults.sample_rate))
    start = int(payload.get("start_idx", 0))
    
    # æ’å¸§ç›¸å…³å‚æ•°
    interpolate = bool(payload.get("interpolate", False))
    original_fps = int(payload.get("original_fps", fps))  # å¦‚æœæœªæŒ‡å®šï¼Œä½¿ç”¨fps
    target_fps = int(payload.get("target_fps", original_fps * 3))  # å¦‚æœæœªæŒ‡å®šï¼Œä½¿ç”¨åŸå§‹å¸§ç‡çš„3å€
    
    torch.manual_seed(seed)
    tmp = Path("/tmp/runpod") / str(time.time_ns())
    tmp.mkdir(parents=True, exist_ok=True)

    # -----------------------------
    # å¤„ç† pose (ç›®å½• or Base-64 ZIP)
    # -----------------------------
    pose_tensor: Optional[torch.Tensor] = None
    pose_field = payload.get("pose")
    
    # ä»Pipelineçš„ç»„ä»¶è·å–dtypeå’Œdeviceï¼Œè€Œä¸æ˜¯Pipelineæœ¬èº«
    dtype = _PIPELINE.vae.dtype
    device = _PIPELINE.vae.device
    
    # 1. å¤„ç†å§¿åŠ¿æ•°æ®
    if pose_field:
        # ç”¨æˆ·æä¾›çš„å§¿åŠ¿å¤„ç†
        if _looks_like_local_file(str(pose_field)) and Path(str(pose_field)).is_dir():
            pose_dir = Path(pose_field)
        else:
            pose_zip = _save_b64_to_tmp(tmp, str(pose_field), ".zip")
            shutil.unpack_archive(pose_zip, tmp / "pose")
            pose_dir = tmp / "pose"

        # å¤„ç†ç”¨æˆ·æä¾›çš„å§¿åŠ¿
        frames = []
        for idx in range(start, start + length):
            pose_file = pose_dir / f"{idx}.npy"
            if not pose_file.exists():
                log.warning(f"å§¿åŠ¿æ–‡ä»¶ä¸å­˜åœ¨: {pose_file}")
                continue
            
            try:
                npy_data = np.load(pose_file, allow_pickle=True).tolist()
                if not isinstance(npy_data, dict) or "draw_pose_params" not in npy_data:
                    log.warning(f"å§¿åŠ¿æ–‡ä»¶æ ¼å¼é”™è¯¯: {pose_file}")
                    continue
                
                imh_new, imw_new, rb, re, cb, ce = npy_data["draw_pose_params"]
                canvas = np.zeros((W, H, 3), dtype="uint8")
                img_pose = draw_pose_select_v2(npy_data, imh_new, imw_new, ref_w=800)
                img_pose = np.transpose(np.array(img_pose), (1, 2, 0))
                canvas[rb:re, cb:ce, :] = img_pose
                frames.append(torch.tensor(canvas, dtype=dtype, device=device).permute(2, 0, 1) / 255.0)
            except Exception as e:
                log.warning(f"å¤„ç†å§¿åŠ¿æ–‡ä»¶å‡ºé”™: {pose_file}, é”™è¯¯: {e}")
                continue
    else:
        # 2. æœªæä¾›å§¿åŠ¿ï¼Œä½¿ç”¨é»˜è®¤å§¿åŠ¿
        log.info("æœªæä¾›å§¿åŠ¿æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å§¿åŠ¿ (assets/halfbody_demo/pose/01)")
        pose_dir = Path("assets/halfbody_demo/pose/01")
        
        if pose_dir.exists():
            # ç¡®ä¿ä¸è¶…è¿‡é»˜è®¤å§¿åŠ¿æ–‡ä»¶æ•°é‡
            avail_poses = sorted([int(p.stem) for p in pose_dir.glob("*.npy") if p.stem.isdigit()])
            if not avail_poses:
                log.warning("é»˜è®¤å§¿åŠ¿ç›®å½•æ²¡æœ‰æœ‰æ•ˆå§¿åŠ¿æ–‡ä»¶")
                frames = []
            else:
                max_idx = max(avail_poses)
                adjusted_length = min(length, len(avail_poses))
                log.info(f"ä½¿ç”¨é»˜è®¤å§¿åŠ¿ï¼Œé•¿åº¦è°ƒæ•´ä¸º: {adjusted_length}")
                
                # å¤„ç†é»˜è®¤å§¿åŠ¿æ–‡ä»¶
                frames = []
                for i in range(adjusted_length):
                    file_idx = start + i
                    if file_idx > max_idx:
                        file_idx = file_idx % (max_idx + 1)  # å¾ªç¯ä½¿ç”¨å§¿åŠ¿
                    
                    pose_file = pose_dir / f"{file_idx}.npy"
                    if not pose_file.exists():
                        continue
                    
                    try:
                        npy_data = np.load(pose_file, allow_pickle=True).tolist()
                        imh_new, imw_new, rb, re, cb, ce = npy_data["draw_pose_params"]
                        canvas = np.zeros((W, H, 3), dtype="uint8")
                        img_pose = draw_pose_select_v2(npy_data, imh_new, imw_new, ref_w=800)
                        img_pose = np.transpose(np.array(img_pose), (1, 2, 0))
                        canvas[rb:re, cb:ce, :] = img_pose
                        frames.append(torch.tensor(canvas, dtype=dtype, device=device).permute(2, 0, 1) / 255.0)
                    except Exception as e:
                        log.warning(f"å¤„ç†é»˜è®¤å§¿åŠ¿æ–‡ä»¶å‡ºé”™: {pose_file}, é”™è¯¯: {e}")
                        continue
        else:
            log.warning(f"é»˜è®¤å§¿åŠ¿ç›®å½•ä¸å­˜åœ¨: {pose_dir}")
            frames = []

    # 3. å¦‚æœæ²¡æœ‰ä»»ä½•æœ‰æ•ˆå§¿åŠ¿å¸§ï¼Œåˆ›å»ºç©ºç™½å§¿åŠ¿
    if not frames:
        log.info("æ²¡æœ‰æœ‰æ•ˆå§¿åŠ¿æ•°æ®ï¼Œä½¿ç”¨ç©ºç™½å§¿åŠ¿")
        empty_frame = torch.zeros((3, W, H), dtype=dtype, device=device)
        frames = [empty_frame for _ in range(length)]

    # ç¡®ä¿å¸§æ•°é‡ä¸è¦æ±‚åŒ¹é…
    if len(frames) < length:
        last_frame = frames[-1] if frames else torch.zeros((3, W, H), dtype=dtype, device=device)
        frames.extend([last_frame] * (length - len(frames)))
    elif len(frames) > length:
        frames = frames[:length]

    pose_tensor = torch.stack(frames, dim=1).unsqueeze(0)
    log.info(f"æœ€ç»ˆå§¿åŠ¿å¼ é‡å½¢çŠ¶: {pose_tensor.shape}")

    # -----------------------------
    # ç”Ÿæˆè§†é¢‘
    # -----------------------------
    videos = _PIPELINE(
        ref_img_pil,
        str(audio_path),
        pose_tensor,  # ç°åœ¨pose_tensorä¸€å®šä¸ä¸ºNone
        W, H, length,
        steps, cfg_scale,
        generator=torch.manual_seed(seed),
        audio_sample_rate=sr,
        context_frames=ctx_f,
        fps=original_fps,  # ä½¿ç”¨åŸå§‹å¸§ç‡ç”Ÿæˆè§†é¢‘
        context_overlap=ctx_o,
        start_idx=start,
    ).videos

    workspace_dir = Path("/workspace/tmp_videos")
    workspace_dir.mkdir(parents=True, exist_ok=True)

    timestamp = int(time.time() * 1000)
    random_suffix = os.urandom(4).hex()
    out_mp4 = workspace_dir / f"vid_{timestamp}_{random_suffix}.mp4"
    enhanced_mp4 = workspace_dir / f"vid_{timestamp}_{random_suffix}_enhanced.mp4"

    try:
        save_videos_grid(videos, str(out_mp4), n_rows=1, fps=original_fps)
        if out_mp4.stat().st_size < 1024:
            raise ValueError("ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è¿‡å°ï¼Œå¯èƒ½ç”Ÿæˆå¤±è´¥")
            
        final_video = out_mp4
        
        # å¦‚æœå¯ç”¨æ’å¸§ï¼Œåˆ™å¯¹è§†é¢‘è¿›è¡Œæ’å¸§å¤„ç†
        if interpolate and target_fps > original_fps:
            try:
                log.info(f"æ­£åœ¨å¯¹è§†é¢‘è¿›è¡Œæ’å¸§: {original_fps}fps â†’ {target_fps}fps")
                _enhance_video_frames(out_mp4, enhanced_mp4, target_fps=target_fps)
                if enhanced_mp4.exists() and enhanced_mp4.stat().st_size > 1024:
                    final_video = enhanced_mp4
                else:
                    log.warning("æ’å¸§å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹è§†é¢‘")
            except Exception as e:
                log.error(f"æ’å¸§è¿‡ç¨‹å‡ºé”™: {e}")
                log.warning("å°†ä½¿ç”¨åŸå§‹è§†é¢‘")
        
        with open(final_video, "rb") as f:
            encoded = base64.b64encode(f.read()).decode()
        return {"video": encoded}
    finally:
        try:
            for f in [out_mp4, enhanced_mp4]:
                if f.exists():
                    f.unlink()
                    log.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {f}")
        except Exception as e:
            log.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

# ---------------------------------------------------------------------
# RunPod Handler
# ---------------------------------------------------------------------

def handler(event: Dict[str, Any]) -> Dict[str, Any]:
    try:
        log.info("â–¶ï¸ New request")
        result = _infer(event.get("input", {}))
        log.info("âœ… Finished")
        return {"success": True, "output": result}
    except Exception as e:
        log.error("âŒ Error %s", e)
        log.debug("Traceback:\n%s", traceback.format_exc())
        return {"success": False, "error": str(e)}

def _ensure_vulkan_installed():
    """ç¡®ä¿Vulkanåº“å·²å®‰è£…"""
    try:
        # å°è¯•å¯¼å…¥vulkanåº“
        subprocess.run(["ldconfig", "-p"], stdout=subprocess.PIPE, text=True, check=True)
        vulkan_check = subprocess.run(
            ["ldconfig", "-p", "|", "grep", "libvulkan"], 
            shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
        )
        
        if vulkan_check.returncode != 0:
            log.info("æ­£åœ¨å®‰è£…Vulkanåº“...")
            subprocess.run(
                ["apt-get", "update", "-y"], 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE, 
                check=True
            )
            subprocess.run(
                ["apt-get", "install", "-y", "libvulkan1"], 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE, 
                check=True
            )
            log.info("Vulkanåº“å®‰è£…å®Œæˆ")
    except Exception as e:
        log.warning(f"Vulkanåº“å®‰è£…å¤±è´¥: {e}")

if __name__ == "__main__":
    log.info("Bootstrapping RunPod server (volume=%s)", VOLUME_ROOT)
    log.info("æ‰§è¡Œé¢„å¯åŠ¨æ¨¡å‹åŠ è½½")
    _download_models()
    _PIPELINE = _build_pipeline()
    runpod.serverless.start({"handler": handler})